{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from GaLa_v5 import llaplace\n",
    "from NN import DNN_Ensemble,DNN,Dropout_DNN\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burgers Equation\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} + u\\frac{\\partial u}{\\partial x} - \\frac{0.01}{\\pi}\\frac{\\partial^{2} u}{\\partial x^{2}}=0$$\n",
    "$$u(x,0) = -sin( \\pi x),  u(-1,t)=u(1,t)=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIREN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(torch.nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = torch.nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "class Siren(torch.nn.Module):\n",
    "    def __init__(self, layers,  \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = len(layers) - 1\n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(layers[0], layers[1], \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(1,self.depth - 1):\n",
    "            self.net.append(\n",
    "                SineLayer(layers[i], layers[i+1], \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        final_linear = torch.nn.Linear(layers[-2], layers[-1])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            final_linear.weight.uniform_(-np.sqrt(6 / layers[-2]) / hidden_omega_0, \n",
    "                                            np.sqrt(6 / layers[-2]) / hidden_omega_0)\n",
    "            \n",
    "            self.net.append(final_linear)\n",
    "\n",
    "        \n",
    "        self.net = torch.nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        #coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        #return output, coords        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de(self,data_domain):\n",
    "    \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "    u = self(data_domain)\n",
    "    \n",
    "    du = torch.autograd.grad(\n",
    "        u, data_domain, \n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    ddu_x = torch.autograd.grad(\n",
    "        du[:,0],data_domain, \n",
    "        grad_outputs=torch.ones_like(du[:,0]),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "        )[0]\n",
    "    \n",
    "    f = du[:,1].reshape(-1,1) + u.reshape(-1,1)*du[:,0].reshape(-1,1) - data_domain[:,2].reshape(-1,1)*ddu_x[:,0].reshape(-1,1)\n",
    "\n",
    "    return f\n",
    "\n",
    "def ini_c(self,data_inic):\n",
    "    u = self(data_inic)\n",
    "    return u + torch.sin(torch.pi*data_inic[:,0].reshape(-1,1))\n",
    "\n",
    "def left_bc(self,data_lbc):\n",
    "    u = self(data_lbc)\n",
    "    return u\n",
    "\n",
    "def right_bc(self,data_rbc):\n",
    "    u = self(data_rbc)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Siren.de = de\n",
    "Siren.ini_c = ini_c\n",
    "Siren.left_bc = left_bc\n",
    "Siren.right_bc = right_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_space(size,maxl=1):\n",
    "    t_f_train = lhs(2, size)*maxl\n",
    "    t_f_train[:,0] = t_f_train[:,0]*(2)-1\n",
    "    t_f_train[:,1] = t_f_train[:,1]*(0.5)\n",
    "    return t_f_train\n",
    "\n",
    "def samples_param(min,max,size = 100):\n",
    "    return np.random.uniform(min,max,size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pde(size,minp,maxp):\n",
    "\n",
    "    xy, param = samples_space(size),samples_param(minp,maxp,(size,1)).reshape(-1,1)\n",
    "    pde_domain = torch.tensor(np.hstack((xy,param.reshape(-1,1)))).float()\n",
    "    \n",
    "    x,y, param  = torch.tensor(xy[:,0]).reshape(-1,1),torch.tensor(xy[:,1]).reshape(-1,1),torch.tensor(param).reshape(-1,1)\n",
    "\n",
    "    ini_c = torch.cat([x,torch.zeros_like(x).float(),param],axis = 1).float()\n",
    "\n",
    "    left_bc = torch.cat([torch.ones_like(x).float()*(-1),y, param],axis = 1).float()\n",
    "\n",
    "    right_bc = torch.cat([torch.ones_like(x).float(),y, param],axis = 1).float()\n",
    "\n",
    "    return pde_domain,ini_c,left_bc,right_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adam(pinn,loss,optimizer,epochs, sample_size = 100,minval_param = 0.2,maxval_param = 2,repetitions=1):\n",
    "      print(\"Starting Adam Training\")\n",
    "      train_loss=[]\n",
    "      for i in range(epochs):\n",
    "        pde_domain,ini_c,left_bc,right_bc = data_pde(sample_size,minval_param,maxval_param)\n",
    "        \n",
    "        pde_domain,ini_c = Variable(pde_domain,requires_grad=True),Variable(ini_c,requires_grad=True)\n",
    "        left_bc,right_bc = Variable(left_bc,requires_grad=True),Variable(right_bc,requires_grad=True)\n",
    "        \n",
    "        for _ in range(repetitions):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pde_pred,ini_c_pred = pinn.de(pde_domain), pinn.ini_c(ini_c)\n",
    "                left_bc_pred,right_bc_pred = pinn.left_bc(left_bc),pinn.right_bc(right_bc)\n",
    "\n",
    "                loss_pde,loss_ini = loss(pde_pred,torch.zeros_like(pde_pred)),loss(ini_c_pred,torch.zeros_like(pde_pred))\n",
    "                loss_lbc,loss_rbc = loss(left_bc_pred,torch.zeros_like(pde_pred)),loss(right_bc_pred,torch.zeros_like(pde_pred))\n",
    "\n",
    "                Loss =  loss_pde + loss_ini + loss_lbc + loss_rbc\n",
    "                train_loss.append(Loss.item())\n",
    "                if i % 10 == 0:\n",
    "                        print('Iter %d, Loss: %.5e, Loss_PDE: %.5e, Loss_ini: %.5e, Loss_lbc: %.5e,Loss_rbc: %.5e' % (i, \n",
    "                                                                         Loss.item(),loss_pde.item(),loss_ini.item(), loss_lbc.item(), loss_rbc.item()))\n",
    "                                \n",
    "                Loss.backward() \n",
    "\n",
    "                optimizer.step() \n",
    "\n",
    "                #sheduler.step()\n",
    "      return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LBFGS(pinn,loss,optimizer, sample_size = 100, minval_param = 0.2,maxval_param = 2):\n",
    "    print(\"Starting Training: LBFGS optimizer\")\n",
    "    train_loss=[]\n",
    "\n",
    "    pde_domain,ini_c,left_bc,right_bc = data_pde(sample_size,minval_param,maxval_param)\n",
    "    \n",
    "    pde_domain,ini_c = Variable(pde_domain,requires_grad=True),Variable(ini_c,requires_grad=True)\n",
    "    left_bc,right_bc = Variable(left_bc,requires_grad=True),Variable(right_bc,requires_grad=True)\n",
    "    \n",
    "\n",
    "    def loss_func_train():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pde_pred,ini_c_pred = pinn.de(pde_domain), pinn.ini_c(ini_c)\n",
    "        left_bc_pred,right_bc_pred = pinn.left_bc(left_bc),pinn.right_bc(right_bc)\n",
    "\n",
    "        loss_pde,loss_ini = loss(pde_pred,torch.zeros_like(pde_pred)),loss(ini_c_pred,torch.zeros_like(pde_pred))\n",
    "        loss_lbc,loss_rbc = loss(left_bc_pred,torch.zeros_like(pde_pred)),loss(right_bc_pred,torch.zeros_like(pde_pred))\n",
    "\n",
    "        Loss =  loss_pde + loss_ini + loss_lbc + loss_rbc\n",
    "        train_loss.append(Loss.item())\n",
    "\n",
    "        print('Loss: %.5e, Loss_PDE: %.5e, Loss_ini: %.5e, Loss_lbc: %.5e,Loss_rbc: %.5e' % ( \n",
    "                                                            Loss.item(),loss_pde.item(),loss_ini.item(), loss_lbc.item(), loss_rbc.item()))\n",
    "\n",
    "        Loss.backward() \n",
    "\n",
    "        return Loss\n",
    "\n",
    "    optimizer.step(loss_func_train) \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations\n",
    "epochs = 1200\n",
    "nobs = 3000\n",
    "#nobs = 500\n",
    "lr = 0.01\n",
    "\n",
    "min_param , max_param = 0.0001, 0.05\n",
    "\n",
    "layers = [3] + 3*[40] + [1]\n",
    "\n",
    "model = Siren(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m pde_domain,ini_c \u001b[38;5;241m=\u001b[39m Variable(pde_domain,requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),Variable(ini_c,requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m left_bc,right_bc \u001b[38;5;241m=\u001b[39m Variable(left_bc,requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),Variable(right_bc,requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m output, coords \u001b[38;5;241m=\u001b[39m model(pde_domain) \n\u001b[0;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[0;32m     10\u001b[0m         output, coords, \n\u001b[0;32m     11\u001b[0m         grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(output),\n\u001b[0;32m     12\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "pde_domain,ini_c,left_bc,right_bc = data_pde(1,min_param , max_param )\n",
    "\n",
    "pde_domain,ini_c = Variable(pde_domain,requires_grad=True),Variable(ini_c,requires_grad=True)\n",
    "left_bc,right_bc = Variable(left_bc,requires_grad=True),Variable(right_bc,requires_grad=True)\n",
    "\n",
    "\n",
    "output, coords = model(pde_domain) \n",
    "\n",
    "torch.autograd.grad(\n",
    "        output, coords, \n",
    "        grad_outputs=torch.ones_like(output),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Adam Training\n",
      "Iter 0, Loss: 5.75205e-01, Loss_PDE: 3.09875e-02, Loss_ini: 5.13586e-01, Loss_lbc: 1.53582e-02,Loss_rbc: 1.52730e-02\n",
      "Iter 10, Loss: 3.28534e+00, Loss_PDE: 2.78377e+00, Loss_ini: 5.01150e-01, Loss_lbc: 1.57936e-04,Loss_rbc: 2.58625e-04\n",
      "Iter 20, Loss: 2.00631e+00, Loss_PDE: 1.50392e+00, Loss_ini: 4.99875e-01, Loss_lbc: 1.26354e-03,Loss_rbc: 1.25079e-03\n",
      "Iter 30, Loss: 8.69518e-01, Loss_PDE: 3.68249e-01, Loss_ini: 5.01032e-01, Loss_lbc: 9.94565e-05,Loss_rbc: 1.37836e-04\n",
      "Iter 40, Loss: 6.42709e-01, Loss_PDE: 1.43838e-01, Loss_ini: 4.98521e-01, Loss_lbc: 1.63679e-04,Loss_rbc: 1.86736e-04\n",
      "Iter 50, Loss: 5.23760e-01, Loss_PDE: 2.36908e-02, Loss_ini: 5.00058e-01, Loss_lbc: 4.61726e-06,Loss_rbc: 6.36716e-06\n",
      "Iter 60, Loss: 5.12559e-01, Loss_PDE: 1.26826e-02, Loss_ini: 4.99848e-01, Loss_lbc: 1.60541e-05,Loss_rbc: 1.16417e-05\n",
      "Iter 70, Loss: 5.03666e-01, Loss_PDE: 3.63953e-03, Loss_ini: 5.00025e-01, Loss_lbc: 9.79305e-07,Loss_rbc: 5.41638e-07\n",
      "Iter 80, Loss: 5.01313e-01, Loss_PDE: 1.72878e-03, Loss_ini: 4.99580e-01, Loss_lbc: 1.97814e-06,Loss_rbc: 2.19767e-06\n",
      "Iter 90, Loss: 5.00390e-01, Loss_PDE: 5.39412e-04, Loss_ini: 4.99851e-01, Loss_lbc: 2.13998e-07,Loss_rbc: 2.39875e-07\n",
      "Iter 100, Loss: 4.99993e-01, Loss_PDE: 4.63362e-04, Loss_ini: 4.99528e-01, Loss_lbc: 5.68984e-07,Loss_rbc: 2.22316e-07\n",
      "Iter 110, Loss: 4.99855e-01, Loss_PDE: 3.01087e-04, Loss_ini: 4.99553e-01, Loss_lbc: 2.54297e-07,Loss_rbc: 2.93083e-07\n",
      "Iter 120, Loss: 4.99765e-01, Loss_PDE: 2.89849e-04, Loss_ini: 4.99475e-01, Loss_lbc: 7.44163e-08,Loss_rbc: 5.87408e-08\n",
      "Iter 130, Loss: 4.99716e-01, Loss_PDE: 3.35829e-04, Loss_ini: 4.99380e-01, Loss_lbc: 1.33793e-07,Loss_rbc: 5.25233e-08\n",
      "Iter 140, Loss: 4.99664e-01, Loss_PDE: 3.43923e-04, Loss_ini: 4.99320e-01, Loss_lbc: 1.01158e-07,Loss_rbc: 1.53892e-07\n",
      "Iter 150, Loss: 4.99575e-01, Loss_PDE: 3.92429e-04, Loss_ini: 4.99182e-01, Loss_lbc: 1.30444e-07,Loss_rbc: 7.80275e-08\n",
      "Iter 160, Loss: 4.99548e-01, Loss_PDE: 5.15587e-04, Loss_ini: 4.99032e-01, Loss_lbc: 1.43727e-07,Loss_rbc: 1.26992e-07\n",
      "Iter 170, Loss: 4.99430e-01, Loss_PDE: 5.37460e-04, Loss_ini: 4.98892e-01, Loss_lbc: 1.53296e-07,Loss_rbc: 1.61839e-07\n",
      "Iter 180, Loss: 4.99413e-01, Loss_PDE: 7.78153e-04, Loss_ini: 4.98634e-01, Loss_lbc: 2.20056e-07,Loss_rbc: 2.22156e-07\n",
      "Iter 190, Loss: 4.99189e-01, Loss_PDE: 7.35293e-04, Loss_ini: 4.98453e-01, Loss_lbc: 2.16416e-07,Loss_rbc: 2.49299e-07\n",
      "Iter 200, Loss: 4.99035e-01, Loss_PDE: 9.61174e-04, Loss_ini: 4.98073e-01, Loss_lbc: 3.14104e-07,Loss_rbc: 3.06908e-07\n",
      "Iter 210, Loss: 4.98836e-01, Loss_PDE: 1.07429e-03, Loss_ini: 4.97761e-01, Loss_lbc: 2.94795e-07,Loss_rbc: 4.16438e-07\n",
      "Iter 220, Loss: 4.98612e-01, Loss_PDE: 1.53811e-03, Loss_ini: 4.97073e-01, Loss_lbc: 4.02162e-07,Loss_rbc: 5.13111e-07\n",
      "Iter 230, Loss: 4.98330e-01, Loss_PDE: 1.66872e-03, Loss_ini: 4.96660e-01, Loss_lbc: 4.71211e-07,Loss_rbc: 5.99088e-07\n",
      "Iter 240, Loss: 4.97850e-01, Loss_PDE: 2.33538e-03, Loss_ini: 4.95513e-01, Loss_lbc: 6.81033e-07,Loss_rbc: 8.92608e-07\n",
      "Iter 250, Loss: 4.97211e-01, Loss_PDE: 2.48985e-03, Loss_ini: 4.94719e-01, Loss_lbc: 9.33883e-07,Loss_rbc: 1.04864e-06\n",
      "Iter 260, Loss: 4.96202e-01, Loss_PDE: 3.17685e-03, Loss_ini: 4.93022e-01, Loss_lbc: 1.33712e-06,Loss_rbc: 1.27769e-06\n",
      "Iter 270, Loss: 4.95345e-01, Loss_PDE: 4.15504e-03, Loss_ini: 4.91187e-01, Loss_lbc: 1.97452e-06,Loss_rbc: 1.71104e-06\n",
      "Iter 280, Loss: 4.93879e-01, Loss_PDE: 5.14460e-03, Loss_ini: 4.88728e-01, Loss_lbc: 3.38525e-06,Loss_rbc: 2.97526e-06\n",
      "Iter 290, Loss: 4.92048e-01, Loss_PDE: 6.03393e-03, Loss_ini: 4.86003e-01, Loss_lbc: 6.35930e-06,Loss_rbc: 5.05308e-06\n",
      "Iter 300, Loss: 4.89702e-01, Loss_PDE: 7.56081e-03, Loss_ini: 4.82119e-01, Loss_lbc: 1.12089e-05,Loss_rbc: 1.11827e-05\n",
      "Iter 310, Loss: 4.86222e-01, Loss_PDE: 9.03512e-03, Loss_ini: 4.77152e-01, Loss_lbc: 1.77168e-05,Loss_rbc: 1.79143e-05\n",
      "Iter 320, Loss: 4.81832e-01, Loss_PDE: 1.21471e-02, Loss_ini: 4.69624e-01, Loss_lbc: 2.87541e-05,Loss_rbc: 3.18364e-05\n",
      "Iter 330, Loss: 4.77163e-01, Loss_PDE: 1.55766e-02, Loss_ini: 4.61501e-01, Loss_lbc: 3.92404e-05,Loss_rbc: 4.58511e-05\n",
      "Iter 340, Loss: 4.71429e-01, Loss_PDE: 2.08650e-02, Loss_ini: 4.50437e-01, Loss_lbc: 6.73168e-05,Loss_rbc: 5.93929e-05\n",
      "Iter 350, Loss: 4.61847e-01, Loss_PDE: 2.27298e-02, Loss_ini: 4.38967e-01, Loss_lbc: 8.14850e-05,Loss_rbc: 6.94526e-05\n",
      "Iter 360, Loss: 4.49509e-01, Loss_PDE: 2.46525e-02, Loss_ini: 4.24641e-01, Loss_lbc: 1.44995e-04,Loss_rbc: 7.08605e-05\n",
      "Iter 370, Loss: 4.31815e-01, Loss_PDE: 2.55230e-02, Loss_ini: 4.05987e-01, Loss_lbc: 2.11649e-04,Loss_rbc: 9.33344e-05\n",
      "Iter 380, Loss: 4.15914e-01, Loss_PDE: 3.54339e-02, Loss_ini: 3.80061e-01, Loss_lbc: 3.36118e-04,Loss_rbc: 8.31191e-05\n",
      "Iter 390, Loss: 4.22382e-01, Loss_PDE: 6.92977e-02, Loss_ini: 3.52569e-01, Loss_lbc: 3.27144e-04,Loss_rbc: 1.88071e-04\n",
      "Iter 400, Loss: 5.35565e-01, Loss_PDE: 1.47602e-01, Loss_ini: 3.86293e-01, Loss_lbc: 1.44139e-03,Loss_rbc: 2.27668e-04\n",
      "Iter 410, Loss: 4.30908e-01, Loss_PDE: 2.66371e-02, Loss_ini: 4.03377e-01, Loss_lbc: 2.63962e-04,Loss_rbc: 6.30240e-04\n",
      "Iter 420, Loss: 3.98332e-01, Loss_PDE: 1.05422e-02, Loss_ini: 3.85856e-01, Loss_lbc: 6.03562e-04,Loss_rbc: 1.32982e-03\n",
      "Iter 430, Loss: 3.40958e-01, Loss_PDE: 7.97730e-03, Loss_ini: 3.32234e-01, Loss_lbc: 4.49231e-04,Loss_rbc: 2.97689e-04\n",
      "Iter 440, Loss: 3.13391e-01, Loss_PDE: 4.47260e-02, Loss_ini: 2.63936e-01, Loss_lbc: 7.51933e-04,Loss_rbc: 3.97635e-03\n",
      "Iter 450, Loss: 4.74050e-01, Loss_PDE: 1.91616e-01, Loss_ini: 2.74997e-01, Loss_lbc: 3.03736e-03,Loss_rbc: 4.39929e-03\n",
      "Iter 460, Loss: 2.02463e+00, Loss_PDE: 1.51949e+00, Loss_ini: 5.03826e-01, Loss_lbc: 4.09833e-04,Loss_rbc: 9.08994e-04\n",
      "Iter 470, Loss: 2.18662e+03, Loss_PDE: 2.18611e+03, Loss_ini: 5.06457e-01, Loss_lbc: 4.57335e-03,Loss_rbc: 4.23085e-03\n",
      "Iter 480, Loss: 2.48790e+05, Loss_PDE: 2.48789e+05, Loss_ini: 5.15560e-01, Loss_lbc: 1.67279e-02,Loss_rbc: 1.62845e-02\n",
      "Iter 490, Loss: 9.45584e+06, Loss_PDE: 9.45584e+06, Loss_ini: 5.48290e-01, Loss_lbc: 4.96117e-02,Loss_rbc: 4.92308e-02\n",
      "Iter 500, Loss: 7.32585e+07, Loss_PDE: 7.32585e+07, Loss_ini: 6.28378e-01, Loss_lbc: 1.26767e-01,Loss_rbc: 1.26940e-01\n",
      "Iter 510, Loss: 5.46579e+08, Loss_PDE: 5.46579e+08, Loss_ini: 5.50414e-01, Loss_lbc: 5.13538e-02,Loss_rbc: 5.13592e-02\n",
      "Iter 520, Loss: 2.29779e+09, Loss_PDE: 2.29779e+09, Loss_ini: 5.80250e-01, Loss_lbc: 8.13448e-02,Loss_rbc: 8.12742e-02\n",
      "Iter 530, Loss: 7.19568e+09, Loss_PDE: 7.19568e+09, Loss_ini: 7.87872e-01, Loss_lbc: 2.87414e-01,Loss_rbc: 2.88441e-01\n",
      "Iter 540, Loss: 2.28554e+10, Loss_PDE: 2.28554e+10, Loss_ini: 9.79797e-01, Loss_lbc: 4.80735e-01,Loss_rbc: 4.79997e-01\n",
      "Iter 550, Loss: 2.15982e+11, Loss_PDE: 2.15982e+11, Loss_ini: 1.07629e+00, Loss_lbc: 5.76151e-01,Loss_rbc: 5.75575e-01\n",
      "Iter 560, Loss: 1.32360e+12, Loss_PDE: 1.32360e+12, Loss_ini: 9.77540e-01, Loss_lbc: 4.78914e-01,Loss_rbc: 4.76840e-01\n",
      "Iter 570, Loss: 2.46284e+12, Loss_PDE: 2.46284e+12, Loss_ini: 1.10556e+00, Loss_lbc: 6.05829e-01,Loss_rbc: 6.06482e-01\n",
      "Iter 580, Loss: 3.42139e+12, Loss_PDE: 3.42139e+12, Loss_ini: 1.08409e+00, Loss_lbc: 5.83862e-01,Loss_rbc: 5.84229e-01\n",
      "Iter 590, Loss: 9.93239e+12, Loss_PDE: 9.93239e+12, Loss_ini: 1.04699e+00, Loss_lbc: 5.46595e-01,Loss_rbc: 5.46621e-01\n",
      "Iter 600, Loss: 1.05967e+13, Loss_PDE: 1.05967e+13, Loss_ini: 8.80903e-01, Loss_lbc: 3.80898e-01,Loss_rbc: 3.80751e-01\n",
      "Iter 610, Loss: 1.60186e+13, Loss_PDE: 1.60186e+13, Loss_ini: 7.08720e-01, Loss_lbc: 2.09058e-01,Loss_rbc: 2.08964e-01\n",
      "Iter 620, Loss: 1.77663e+13, Loss_PDE: 1.77663e+13, Loss_ini: 6.26068e-01, Loss_lbc: 1.25954e-01,Loss_rbc: 1.25936e-01\n",
      "Iter 630, Loss: 3.36535e+13, Loss_PDE: 3.36535e+13, Loss_ini: 7.18972e-01, Loss_lbc: 2.18572e-01,Loss_rbc: 2.18798e-01\n",
      "Iter 640, Loss: 2.52125e+13, Loss_PDE: 2.52125e+13, Loss_ini: 8.29226e-01, Loss_lbc: 3.29132e-01,Loss_rbc: 3.29536e-01\n",
      "Iter 650, Loss: 1.80648e+13, Loss_PDE: 1.80648e+13, Loss_ini: 9.10295e-01, Loss_lbc: 4.10224e-01,Loss_rbc: 4.10505e-01\n",
      "Iter 660, Loss: 1.09645e+13, Loss_PDE: 1.09645e+13, Loss_ini: 9.42459e-01, Loss_lbc: 4.42022e-01,Loss_rbc: 4.42088e-01\n",
      "Iter 670, Loss: 1.06180e+13, Loss_PDE: 1.06180e+13, Loss_ini: 9.65572e-01, Loss_lbc: 4.65302e-01,Loss_rbc: 4.65395e-01\n",
      "Iter 680, Loss: 7.62160e+12, Loss_PDE: 7.62160e+12, Loss_ini: 9.77300e-01, Loss_lbc: 4.77348e-01,Loss_rbc: 4.77238e-01\n",
      "Iter 690, Loss: 9.63940e+12, Loss_PDE: 9.63940e+12, Loss_ini: 9.49885e-01, Loss_lbc: 4.49818e-01,Loss_rbc: 4.49481e-01\n",
      "Iter 700, Loss: 5.74926e+12, Loss_PDE: 5.74926e+12, Loss_ini: 9.23975e-01, Loss_lbc: 4.23576e-01,Loss_rbc: 4.23571e-01\n",
      "Iter 710, Loss: 4.14759e+12, Loss_PDE: 4.14759e+12, Loss_ini: 8.88512e-01, Loss_lbc: 3.88330e-01,Loss_rbc: 3.88545e-01\n",
      "Iter 720, Loss: 2.65364e+12, Loss_PDE: 2.65364e+12, Loss_ini: 8.63634e-01, Loss_lbc: 3.63729e-01,Loss_rbc: 3.63711e-01\n",
      "Iter 730, Loss: 2.19465e+12, Loss_PDE: 2.19465e+12, Loss_ini: 8.52511e-01, Loss_lbc: 3.52399e-01,Loss_rbc: 3.52410e-01\n",
      "Iter 740, Loss: 1.54212e+12, Loss_PDE: 1.54212e+12, Loss_ini: 8.49162e-01, Loss_lbc: 3.49155e-01,Loss_rbc: 3.49131e-01\n",
      "Iter 750, Loss: 1.28294e+12, Loss_PDE: 1.28294e+12, Loss_ini: 8.48043e-01, Loss_lbc: 3.48053e-01,Loss_rbc: 3.48134e-01\n",
      "Iter 760, Loss: 5.34614e+11, Loss_PDE: 5.34614e+11, Loss_ini: 8.47697e-01, Loss_lbc: 3.47748e-01,Loss_rbc: 3.47671e-01\n",
      "Iter 770, Loss: 3.43602e+11, Loss_PDE: 3.43602e+11, Loss_ini: 8.48320e-01, Loss_lbc: 3.48288e-01,Loss_rbc: 3.48327e-01\n",
      "Iter 780, Loss: 1.59802e+11, Loss_PDE: 1.59802e+11, Loss_ini: 8.48264e-01, Loss_lbc: 3.48237e-01,Loss_rbc: 3.48283e-01\n",
      "Iter 790, Loss: 1.16324e+11, Loss_PDE: 1.16324e+11, Loss_ini: 8.47896e-01, Loss_lbc: 3.47911e-01,Loss_rbc: 3.47871e-01\n",
      "Iter 800, Loss: 9.35436e+10, Loss_PDE: 9.35436e+10, Loss_ini: 8.47233e-01, Loss_lbc: 3.47243e-01,Loss_rbc: 3.47261e-01\n",
      "Iter 810, Loss: 1.04685e+11, Loss_PDE: 1.04685e+11, Loss_ini: 8.46878e-01, Loss_lbc: 3.46909e-01,Loss_rbc: 3.46904e-01\n",
      "Iter 820, Loss: 1.54823e+11, Loss_PDE: 1.54823e+11, Loss_ini: 8.47299e-01, Loss_lbc: 3.47212e-01,Loss_rbc: 3.47255e-01\n",
      "Iter 830, Loss: 1.34942e+11, Loss_PDE: 1.34942e+11, Loss_ini: 8.47148e-01, Loss_lbc: 3.47153e-01,Loss_rbc: 3.47163e-01\n",
      "Iter 840, Loss: 8.16368e+10, Loss_PDE: 8.16368e+10, Loss_ini: 8.46837e-01, Loss_lbc: 3.46794e-01,Loss_rbc: 3.46789e-01\n",
      "Iter 850, Loss: 7.03064e+10, Loss_PDE: 7.03064e+10, Loss_ini: 8.46564e-01, Loss_lbc: 3.46570e-01,Loss_rbc: 3.46570e-01\n",
      "Iter 860, Loss: 6.43742e+10, Loss_PDE: 6.43742e+10, Loss_ini: 8.46680e-01, Loss_lbc: 3.46712e-01,Loss_rbc: 3.46703e-01\n",
      "Iter 870, Loss: 8.20904e+10, Loss_PDE: 8.20904e+10, Loss_ini: 8.46684e-01, Loss_lbc: 3.46700e-01,Loss_rbc: 3.46695e-01\n",
      "Iter 880, Loss: 5.83933e+10, Loss_PDE: 5.83933e+10, Loss_ini: 8.46924e-01, Loss_lbc: 3.46908e-01,Loss_rbc: 3.46897e-01\n",
      "Iter 890, Loss: 4.69248e+10, Loss_PDE: 4.69248e+10, Loss_ini: 8.47064e-01, Loss_lbc: 3.47084e-01,Loss_rbc: 3.47067e-01\n",
      "Iter 900, Loss: 3.00725e+10, Loss_PDE: 3.00725e+10, Loss_ini: 8.47130e-01, Loss_lbc: 3.47115e-01,Loss_rbc: 3.47117e-01\n",
      "Iter 910, Loss: 3.61741e+10, Loss_PDE: 3.61741e+10, Loss_ini: 8.47263e-01, Loss_lbc: 3.47264e-01,Loss_rbc: 3.47251e-01\n",
      "Iter 920, Loss: 2.88084e+10, Loss_PDE: 2.88084e+10, Loss_ini: 8.47294e-01, Loss_lbc: 3.47285e-01,Loss_rbc: 3.47280e-01\n",
      "Iter 930, Loss: 3.23702e+10, Loss_PDE: 3.23702e+10, Loss_ini: 8.47288e-01, Loss_lbc: 3.47292e-01,Loss_rbc: 3.47297e-01\n",
      "Iter 940, Loss: 7.51993e+10, Loss_PDE: 7.51993e+10, Loss_ini: 8.47423e-01, Loss_lbc: 3.47404e-01,Loss_rbc: 3.47404e-01\n",
      "Iter 950, Loss: 3.73088e+10, Loss_PDE: 3.73088e+10, Loss_ini: 8.47451e-01, Loss_lbc: 3.47459e-01,Loss_rbc: 3.47453e-01\n",
      "Iter 960, Loss: 2.86185e+10, Loss_PDE: 2.86185e+10, Loss_ini: 8.47352e-01, Loss_lbc: 3.47352e-01,Loss_rbc: 3.47333e-01\n",
      "Iter 970, Loss: 2.86853e+10, Loss_PDE: 2.86853e+10, Loss_ini: 8.47206e-01, Loss_lbc: 3.47197e-01,Loss_rbc: 3.47203e-01\n",
      "Iter 980, Loss: 3.59464e+10, Loss_PDE: 3.59464e+10, Loss_ini: 8.47124e-01, Loss_lbc: 3.47100e-01,Loss_rbc: 3.47112e-01\n",
      "Iter 990, Loss: 3.60573e+10, Loss_PDE: 3.60573e+10, Loss_ini: 8.47069e-01, Loss_lbc: 3.47064e-01,Loss_rbc: 3.47063e-01\n",
      "Iter 1000, Loss: 5.89285e+10, Loss_PDE: 5.89285e+10, Loss_ini: 8.46973e-01, Loss_lbc: 3.46957e-01,Loss_rbc: 3.46953e-01\n",
      "Iter 1010, Loss: 5.52889e+10, Loss_PDE: 5.52889e+10, Loss_ini: 8.46869e-01, Loss_lbc: 3.46883e-01,Loss_rbc: 3.46856e-01\n",
      "Iter 1020, Loss: 6.07822e+10, Loss_PDE: 6.07822e+10, Loss_ini: 8.46959e-01, Loss_lbc: 3.46940e-01,Loss_rbc: 3.46950e-01\n",
      "Iter 1030, Loss: 3.91035e+10, Loss_PDE: 3.91035e+10, Loss_ini: 8.46848e-01, Loss_lbc: 3.46871e-01,Loss_rbc: 3.46859e-01\n",
      "Iter 1040, Loss: 6.66463e+10, Loss_PDE: 6.66463e+10, Loss_ini: 8.46647e-01, Loss_lbc: 3.46637e-01,Loss_rbc: 3.46625e-01\n",
      "Iter 1050, Loss: 6.75736e+10, Loss_PDE: 6.75736e+10, Loss_ini: 8.46527e-01, Loss_lbc: 3.46527e-01,Loss_rbc: 3.46521e-01\n",
      "Iter 1060, Loss: 7.92952e+10, Loss_PDE: 7.92952e+10, Loss_ini: 8.46337e-01, Loss_lbc: 3.46347e-01,Loss_rbc: 3.46378e-01\n",
      "Iter 1070, Loss: 2.09003e+11, Loss_PDE: 2.09003e+11, Loss_ini: 8.46494e-01, Loss_lbc: 3.46519e-01,Loss_rbc: 3.46495e-01\n",
      "Iter 1080, Loss: 2.64403e+11, Loss_PDE: 2.64403e+11, Loss_ini: 8.46985e-01, Loss_lbc: 3.47012e-01,Loss_rbc: 3.47065e-01\n",
      "Iter 1090, Loss: 2.28801e+11, Loss_PDE: 2.28801e+11, Loss_ini: 8.46773e-01, Loss_lbc: 3.46756e-01,Loss_rbc: 3.46779e-01\n",
      "Iter 1100, Loss: 2.29378e+11, Loss_PDE: 2.29378e+11, Loss_ini: 8.46589e-01, Loss_lbc: 3.46582e-01,Loss_rbc: 3.46577e-01\n",
      "Iter 1110, Loss: 2.40768e+11, Loss_PDE: 2.40768e+11, Loss_ini: 8.46431e-01, Loss_lbc: 3.46439e-01,Loss_rbc: 3.46443e-01\n",
      "Iter 1120, Loss: 2.81672e+11, Loss_PDE: 2.81672e+11, Loss_ini: 8.45983e-01, Loss_lbc: 3.45933e-01,Loss_rbc: 3.45997e-01\n",
      "Iter 1130, Loss: 3.49951e+11, Loss_PDE: 3.49951e+11, Loss_ini: 8.44888e-01, Loss_lbc: 3.44822e-01,Loss_rbc: 3.44805e-01\n",
      "Iter 1140, Loss: 5.84110e+11, Loss_PDE: 5.84110e+11, Loss_ini: 8.46651e-01, Loss_lbc: 3.46618e-01,Loss_rbc: 3.46711e-01\n",
      "Iter 1150, Loss: 7.34194e+11, Loss_PDE: 7.34194e+11, Loss_ini: 8.46017e-01, Loss_lbc: 3.46099e-01,Loss_rbc: 3.46077e-01\n",
      "Iter 1160, Loss: 1.36010e+12, Loss_PDE: 1.36010e+12, Loss_ini: 8.40851e-01, Loss_lbc: 3.40687e-01,Loss_rbc: 3.40762e-01\n",
      "Iter 1170, Loss: 2.14581e+12, Loss_PDE: 2.14581e+12, Loss_ini: 8.36353e-01, Loss_lbc: 3.36521e-01,Loss_rbc: 3.36377e-01\n",
      "Iter 1180, Loss: 2.02276e+12, Loss_PDE: 2.02276e+12, Loss_ini: 8.26766e-01, Loss_lbc: 3.26770e-01,Loss_rbc: 3.26776e-01\n",
      "Iter 1190, Loss: 1.28803e+12, Loss_PDE: 1.28803e+12, Loss_ini: 8.16495e-01, Loss_lbc: 3.16435e-01,Loss_rbc: 3.16566e-01\n",
      "Starting Training: LBFGS optimizer\n",
      "Loss: 6.12185e+11, Loss_PDE: 6.12185e+11, Loss_ini: 8.12904e-01, Loss_lbc: 3.12912e-01,Loss_rbc: 3.12907e-01\n",
      "Loss: 4.94542e+11, Loss_PDE: 4.94542e+11, Loss_ini: 8.12847e-01, Loss_lbc: 3.12919e-01,Loss_rbc: 3.12881e-01\n",
      "Loss: 4.74898e+11, Loss_PDE: 4.74898e+11, Loss_ini: 8.12843e-01, Loss_lbc: 3.12922e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 4.53369e+11, Loss_PDE: 4.53369e+11, Loss_ini: 8.12835e-01, Loss_lbc: 3.12921e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 4.50620e+11, Loss_PDE: 4.50620e+11, Loss_ini: 8.12834e-01, Loss_lbc: 3.12922e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 4.40330e+11, Loss_PDE: 4.40330e+11, Loss_ini: 8.12830e-01, Loss_lbc: 3.12923e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 4.39999e+11, Loss_PDE: 4.39999e+11, Loss_ini: 8.12830e-01, Loss_lbc: 3.12923e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 4.37857e+11, Loss_PDE: 4.37857e+11, Loss_ini: 8.12830e-01, Loss_lbc: 3.12923e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 4.27264e+11, Loss_PDE: 4.27264e+11, Loss_ini: 8.12825e-01, Loss_lbc: 3.12922e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 4.26826e+11, Loss_PDE: 4.26826e+11, Loss_ini: 8.12825e-01, Loss_lbc: 3.12922e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 4.23507e+11, Loss_PDE: 4.23507e+11, Loss_ini: 8.12824e-01, Loss_lbc: 3.12921e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.20084e+11, Loss_PDE: 4.20084e+11, Loss_ini: 8.12822e-01, Loss_lbc: 3.12921e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 3.97779e+11, Loss_PDE: 3.97779e+11, Loss_ini: 8.12810e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12896e-01\n",
      "Loss: 3.97560e+11, Loss_PDE: 3.97560e+11, Loss_ini: 8.12810e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12896e-01\n",
      "Loss: 3.95800e+11, Loss_PDE: 3.95800e+11, Loss_ini: 8.12810e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 3.95151e+11, Loss_PDE: 3.95151e+11, Loss_ini: 8.12809e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 3.86612e+11, Loss_PDE: 3.86612e+11, Loss_ini: 8.12808e-01, Loss_lbc: 3.12914e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.86491e+11, Loss_PDE: 3.86491e+11, Loss_ini: 8.12808e-01, Loss_lbc: 3.12914e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.85048e+11, Loss_PDE: 3.85048e+11, Loss_ini: 8.12808e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.84432e+11, Loss_PDE: 3.84432e+11, Loss_ini: 8.12808e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.77280e+11, Loss_PDE: 3.77280e+11, Loss_ini: 8.12809e-01, Loss_lbc: 3.12916e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 3.77077e+11, Loss_PDE: 3.77077e+11, Loss_ini: 8.12809e-01, Loss_lbc: 3.12916e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 3.75981e+11, Loss_PDE: 3.75981e+11, Loss_ini: 8.12810e-01, Loss_lbc: 3.12916e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 3.70733e+11, Loss_PDE: 3.70733e+11, Loss_ini: 8.12812e-01, Loss_lbc: 3.12918e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.70124e+11, Loss_PDE: 3.70124e+11, Loss_ini: 8.12812e-01, Loss_lbc: 3.12918e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.69889e+11, Loss_PDE: 3.69889e+11, Loss_ini: 8.12812e-01, Loss_lbc: 3.12918e-01,Loss_rbc: 3.12902e-01\n",
      "Loss: 3.66556e+11, Loss_PDE: 3.66556e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12919e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 3.66280e+11, Loss_PDE: 3.66280e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12920e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 3.63868e+11, Loss_PDE: 3.63868e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12921e-01,Loss_rbc: 3.12900e-01\n",
      "Loss: 3.62102e+11, Loss_PDE: 3.62102e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12921e-01,Loss_rbc: 3.12900e-01\n",
      "Loss: 3.61677e+11, Loss_PDE: 3.61677e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12922e-01,Loss_rbc: 3.12900e-01\n",
      "Loss: 3.59667e+11, Loss_PDE: 3.59667e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12923e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 3.50918e+11, Loss_PDE: 3.50918e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12896e-01\n",
      "Loss: 3.50755e+11, Loss_PDE: 3.50755e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12896e-01\n",
      "Loss: 3.49658e+11, Loss_PDE: 3.49658e+11, Loss_ini: 8.12812e-01, Loss_lbc: 3.12929e-01,Loss_rbc: 3.12896e-01\n",
      "Loss: 3.47874e+11, Loss_PDE: 3.47874e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12930e-01,Loss_rbc: 3.12895e-01\n",
      "Loss: 3.47673e+11, Loss_PDE: 3.47673e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12930e-01,Loss_rbc: 3.12895e-01\n",
      "Loss: 3.46583e+11, Loss_PDE: 3.46583e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12931e-01,Loss_rbc: 3.12895e-01\n",
      "Loss: 3.41458e+11, Loss_PDE: 3.41458e+11, Loss_ini: 8.12811e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12893e-01\n",
      "Loss: 3.41207e+11, Loss_PDE: 3.41207e+11, Loss_ini: 8.12811e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12893e-01\n",
      "Loss: 3.40197e+11, Loss_PDE: 3.40197e+11, Loss_ini: 8.12812e-01, Loss_lbc: 3.12935e-01,Loss_rbc: 3.12893e-01\n",
      "Loss: 3.35055e+11, Loss_PDE: 3.35055e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12939e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.34879e+11, Loss_PDE: 3.34879e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12939e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.34725e+11, Loss_PDE: 3.34725e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12939e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.33004e+11, Loss_PDE: 3.33004e+11, Loss_ini: 8.12814e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.32885e+11, Loss_PDE: 3.32885e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.32093e+11, Loss_PDE: 3.32093e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.27746e+11, Loss_PDE: 3.27746e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 3.27498e+11, Loss_PDE: 3.27498e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 3.27388e+11, Loss_PDE: 3.27388e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 3.25935e+11, Loss_PDE: 3.25935e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.25669e+11, Loss_PDE: 3.25669e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 3.25682e+11, Loss_PDE: 3.25682e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.25682e+11, Loss_PDE: 3.25682e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.24170e+11, Loss_PDE: 3.24170e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12941e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.22746e+11, Loss_PDE: 3.22746e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.22435e+11, Loss_PDE: 3.22435e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.22411e+11, Loss_PDE: 3.22411e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.22410e+11, Loss_PDE: 3.22410e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 3.20822e+11, Loss_PDE: 3.20822e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.20487e+11, Loss_PDE: 3.20487e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.20357e+11, Loss_PDE: 3.20357e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.20339e+11, Loss_PDE: 3.20339e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12940e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.18729e+11, Loss_PDE: 3.18729e+11, Loss_ini: 8.12813e-01, Loss_lbc: 3.12939e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 3.11939e+11, Loss_PDE: 3.11939e+11, Loss_ini: 8.12817e-01, Loss_lbc: 3.12937e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 3.11830e+11, Loss_PDE: 3.11830e+11, Loss_ini: 8.12817e-01, Loss_lbc: 3.12937e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 3.11280e+11, Loss_PDE: 3.11280e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12936e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 3.07596e+11, Loss_PDE: 3.07596e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12935e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 3.07499e+11, Loss_PDE: 3.07499e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12935e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 3.06524e+11, Loss_PDE: 3.06524e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12935e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 3.06225e+11, Loss_PDE: 3.06225e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12935e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 3.01587e+11, Loss_PDE: 3.01587e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 3.01463e+11, Loss_PDE: 3.01463e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 3.00689e+11, Loss_PDE: 3.00689e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 3.00196e+11, Loss_PDE: 3.00196e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 2.99859e+11, Loss_PDE: 2.99859e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 2.99685e+11, Loss_PDE: 2.99685e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 2.99420e+11, Loss_PDE: 2.99420e+11, Loss_ini: 8.12824e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 2.97983e+11, Loss_PDE: 2.97983e+11, Loss_ini: 8.12824e-01, Loss_lbc: 3.12934e-01,Loss_rbc: 3.12901e-01\n",
      "Loss: 2.91438e+11, Loss_PDE: 2.91438e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12933e-01,Loss_rbc: 3.12900e-01\n",
      "Loss: 2.91272e+11, Loss_PDE: 2.91272e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12933e-01,Loss_rbc: 3.12900e-01\n",
      "Loss: 2.90273e+11, Loss_PDE: 2.90273e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12933e-01,Loss_rbc: 3.12900e-01\n",
      "Loss: 2.89262e+11, Loss_PDE: 2.89262e+11, Loss_ini: 8.12823e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.89106e+11, Loss_PDE: 2.89106e+11, Loss_ini: 8.12822e-01, Loss_lbc: 3.12933e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.88133e+11, Loss_PDE: 2.88133e+11, Loss_ini: 8.12822e-01, Loss_lbc: 3.12933e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.83575e+11, Loss_PDE: 2.83575e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.83481e+11, Loss_PDE: 2.83481e+11, Loss_ini: 8.12819e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.82653e+11, Loss_PDE: 2.82653e+11, Loss_ini: 8.12819e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.82113e+11, Loss_PDE: 2.82113e+11, Loss_ini: 8.12819e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.81963e+11, Loss_PDE: 2.81963e+11, Loss_ini: 8.12819e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.80959e+11, Loss_PDE: 2.80959e+11, Loss_ini: 8.12819e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.80340e+11, Loss_PDE: 2.80340e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12933e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.79844e+11, Loss_PDE: 2.79844e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.79563e+11, Loss_PDE: 2.79563e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12897e-01\n",
      "Loss: 2.79381e+11, Loss_PDE: 2.79381e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.79203e+11, Loss_PDE: 2.79203e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.76501e+11, Loss_PDE: 2.76501e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.76334e+11, Loss_PDE: 2.76334e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.75251e+11, Loss_PDE: 2.75251e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.74318e+11, Loss_PDE: 2.74318e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.73993e+11, Loss_PDE: 2.73993e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12898e-01\n",
      "Loss: 2.73808e+11, Loss_PDE: 2.73808e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.73785e+11, Loss_PDE: 2.73785e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.71973e+11, Loss_PDE: 2.71973e+11, Loss_ini: 8.12818e-01, Loss_lbc: 3.12932e-01,Loss_rbc: 3.12899e-01\n",
      "Loss: 2.64395e+11, Loss_PDE: 2.64395e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12929e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.64295e+11, Loss_PDE: 2.64295e+11, Loss_ini: 8.12820e-01, Loss_lbc: 3.12929e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.63672e+11, Loss_PDE: 2.63672e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12929e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.63021e+11, Loss_PDE: 2.63021e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12929e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.62905e+11, Loss_PDE: 2.62905e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12929e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.62033e+11, Loss_PDE: 2.62033e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.61169e+11, Loss_PDE: 2.61169e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.59609e+11, Loss_PDE: 2.59609e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.59255e+11, Loss_PDE: 2.59255e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.59113e+11, Loss_PDE: 2.59113e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.59029e+11, Loss_PDE: 2.59029e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58997e+11, Loss_PDE: 2.58997e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58998e+11, Loss_PDE: 2.58998e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12927e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58994e+11, Loss_PDE: 2.58994e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58993e+11, Loss_PDE: 2.58993e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58992e+11, Loss_PDE: 2.58992e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58992e+11, Loss_PDE: 2.58992e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.58992e+11, Loss_PDE: 2.58992e+11, Loss_ini: 8.12821e-01, Loss_lbc: 3.12928e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.57348e+11, Loss_PDE: 2.57348e+11, Loss_ini: 8.12822e-01, Loss_lbc: 3.12927e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.50682e+11, Loss_PDE: 2.50682e+11, Loss_ini: 8.12825e-01, Loss_lbc: 3.12924e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.50280e+11, Loss_PDE: 2.50280e+11, Loss_ini: 8.12825e-01, Loss_lbc: 3.12923e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.48491e+11, Loss_PDE: 2.48491e+11, Loss_ini: 8.12826e-01, Loss_lbc: 3.12922e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.40064e+11, Loss_PDE: 2.40064e+11, Loss_ini: 8.12832e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.39757e+11, Loss_PDE: 2.39757e+11, Loss_ini: 8.12833e-01, Loss_lbc: 3.12915e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.38296e+11, Loss_PDE: 2.38296e+11, Loss_ini: 8.12834e-01, Loss_lbc: 3.12914e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.31149e+11, Loss_PDE: 2.31149e+11, Loss_ini: 8.12842e-01, Loss_lbc: 3.12907e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.30751e+11, Loss_PDE: 2.30751e+11, Loss_ini: 8.12842e-01, Loss_lbc: 3.12907e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.29054e+11, Loss_PDE: 2.29054e+11, Loss_ini: 8.12844e-01, Loss_lbc: 3.12906e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.26479e+11, Loss_PDE: 2.26479e+11, Loss_ini: 8.12846e-01, Loss_lbc: 3.12905e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 2.23151e+11, Loss_PDE: 2.23151e+11, Loss_ini: 8.12850e-01, Loss_lbc: 3.12903e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.22440e+11, Loss_PDE: 2.22440e+11, Loss_ini: 8.12851e-01, Loss_lbc: 3.12903e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.19097e+11, Loss_PDE: 2.19097e+11, Loss_ini: 8.12855e-01, Loss_lbc: 3.12900e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.07236e+11, Loss_PDE: 2.07236e+11, Loss_ini: 8.12870e-01, Loss_lbc: 3.12895e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.06821e+11, Loss_PDE: 2.06821e+11, Loss_ini: 8.12871e-01, Loss_lbc: 3.12896e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.04456e+11, Loss_PDE: 2.04456e+11, Loss_ini: 8.12873e-01, Loss_lbc: 3.12895e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.02922e+11, Loss_PDE: 2.02922e+11, Loss_ini: 8.12876e-01, Loss_lbc: 3.12895e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.02534e+11, Loss_PDE: 2.02534e+11, Loss_ini: 8.12876e-01, Loss_lbc: 3.12895e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 2.00357e+11, Loss_PDE: 2.00357e+11, Loss_ini: 8.12878e-01, Loss_lbc: 3.12896e-01,Loss_rbc: 3.12903e-01\n",
      "Loss: 1.97806e+11, Loss_PDE: 1.97806e+11, Loss_ini: 8.12881e-01, Loss_lbc: 3.12897e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 1.97334e+11, Loss_PDE: 1.97334e+11, Loss_ini: 8.12882e-01, Loss_lbc: 3.12897e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 1.95112e+11, Loss_PDE: 1.95112e+11, Loss_ini: 8.12884e-01, Loss_lbc: 3.12898e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 1.91724e+11, Loss_PDE: 1.91724e+11, Loss_ini: 8.12887e-01, Loss_lbc: 3.12899e-01,Loss_rbc: 3.12904e-01\n",
      "Loss: 1.91216e+11, Loss_PDE: 1.91216e+11, Loss_ini: 8.12887e-01, Loss_lbc: 3.12899e-01,Loss_rbc: 3.12905e-01\n",
      "Loss: 1.90936e+11, Loss_PDE: 1.90936e+11, Loss_ini: 8.12888e-01, Loss_lbc: 3.12899e-01,Loss_rbc: 3.12905e-01\n",
      "Loss: 1.87486e+11, Loss_PDE: 1.87486e+11, Loss_ini: 8.12890e-01, Loss_lbc: 3.12900e-01,Loss_rbc: 3.12905e-01\n",
      "Loss: 1.86906e+11, Loss_PDE: 1.86906e+11, Loss_ini: 8.12890e-01, Loss_lbc: 3.12900e-01,Loss_rbc: 3.12905e-01\n",
      "Loss: 1.86513e+11, Loss_PDE: 1.86513e+11, Loss_ini: 8.12891e-01, Loss_lbc: 3.12900e-01,Loss_rbc: 3.12905e-01\n",
      "Loss: 1.81707e+11, Loss_PDE: 1.81707e+11, Loss_ini: 8.12893e-01, Loss_lbc: 3.12901e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.80970e+11, Loss_PDE: 1.80970e+11, Loss_ini: 8.12893e-01, Loss_lbc: 3.12901e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.80180e+11, Loss_PDE: 1.80180e+11, Loss_ini: 8.12894e-01, Loss_lbc: 3.12901e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.73598e+11, Loss_PDE: 1.73598e+11, Loss_ini: 8.12896e-01, Loss_lbc: 3.12902e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.72844e+11, Loss_PDE: 1.72844e+11, Loss_ini: 8.12896e-01, Loss_lbc: 3.12902e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.69440e+11, Loss_PDE: 1.69440e+11, Loss_ini: 8.12897e-01, Loss_lbc: 3.12902e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.53037e+11, Loss_PDE: 1.53037e+11, Loss_ini: 8.12901e-01, Loss_lbc: 3.12904e-01,Loss_rbc: 3.12907e-01\n",
      "Loss: 1.52136e+11, Loss_PDE: 1.52136e+11, Loss_ini: 8.12901e-01, Loss_lbc: 3.12904e-01,Loss_rbc: 3.12907e-01\n",
      "Loss: 1.49876e+11, Loss_PDE: 1.49876e+11, Loss_ini: 8.12901e-01, Loss_lbc: 3.12904e-01,Loss_rbc: 3.12906e-01\n",
      "Loss: 1.40156e+11, Loss_PDE: 1.40156e+11, Loss_ini: 8.12901e-01, Loss_lbc: 3.12903e-01,Loss_rbc: 3.12905e-01\n",
      "Loss: 9.92396e+10, Loss_PDE: 9.92396e+10, Loss_ini: 8.12876e-01, Loss_lbc: 3.12898e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 9.88163e+10, Loss_PDE: 9.88163e+10, Loss_ini: 8.12876e-01, Loss_lbc: 3.12898e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 9.68074e+10, Loss_PDE: 9.68074e+10, Loss_ini: 8.12875e-01, Loss_lbc: 3.12897e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 8.82361e+10, Loss_PDE: 8.82361e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12893e-01,Loss_rbc: 3.12881e-01\n",
      "Loss: 8.78995e+10, Loss_PDE: 8.78995e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12893e-01,Loss_rbc: 3.12881e-01\n",
      "Loss: 8.66652e+10, Loss_PDE: 8.66652e+10, Loss_ini: 8.12868e-01, Loss_lbc: 3.12892e-01,Loss_rbc: 3.12882e-01\n",
      "Loss: 8.09567e+10, Loss_PDE: 8.09567e+10, Loss_ini: 8.12865e-01, Loss_lbc: 3.12889e-01,Loss_rbc: 3.12883e-01\n",
      "Loss: 8.08222e+10, Loss_PDE: 8.08222e+10, Loss_ini: 8.12865e-01, Loss_lbc: 3.12889e-01,Loss_rbc: 3.12883e-01\n",
      "Loss: 8.00976e+10, Loss_PDE: 8.00976e+10, Loss_ini: 8.12865e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12884e-01\n",
      "Loss: 7.92130e+10, Loss_PDE: 7.92130e+10, Loss_ini: 8.12865e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12884e-01\n",
      "Loss: 7.90736e+10, Loss_PDE: 7.90736e+10, Loss_ini: 8.12865e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 7.83739e+10, Loss_PDE: 7.83739e+10, Loss_ini: 8.12865e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 7.75319e+10, Loss_PDE: 7.75319e+10, Loss_ini: 8.12864e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 7.26542e+10, Loss_PDE: 7.26542e+10, Loss_ini: 8.12866e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 7.26017e+10, Loss_PDE: 7.26017e+10, Loss_ini: 8.12866e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 7.23329e+10, Loss_PDE: 7.23329e+10, Loss_ini: 8.12866e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 7.19498e+10, Loss_PDE: 7.19498e+10, Loss_ini: 8.12866e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 7.13977e+10, Loss_PDE: 7.13977e+10, Loss_ini: 8.12867e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 7.12182e+10, Loss_PDE: 7.12182e+10, Loss_ini: 8.12867e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 7.03879e+10, Loss_PDE: 7.03879e+10, Loss_ini: 8.12867e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.85539e+10, Loss_PDE: 6.85539e+10, Loss_ini: 8.12868e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 6.83761e+10, Loss_PDE: 6.83761e+10, Loss_ini: 8.12868e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 6.81678e+10, Loss_PDE: 6.81678e+10, Loss_ini: 8.12868e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 6.65770e+10, Loss_PDE: 6.65770e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 6.64346e+10, Loss_PDE: 6.64346e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 6.58734e+10, Loss_PDE: 6.58734e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.29605e+10, Loss_PDE: 6.29605e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.28641e+10, Loss_PDE: 6.28641e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.24204e+10, Loss_PDE: 6.24204e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.16306e+10, Loss_PDE: 6.16306e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.14830e+10, Loss_PDE: 6.14830e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.13928e+10, Loss_PDE: 6.13928e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.13547e+10, Loss_PDE: 6.13547e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 6.03044e+10, Loss_PDE: 6.03044e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 5.60791e+10, Loss_PDE: 5.60791e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.59976e+10, Loss_PDE: 5.59976e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.58979e+10, Loss_PDE: 5.58979e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.50819e+10, Loss_PDE: 5.50819e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.25644e+10, Loss_PDE: 5.25644e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.24444e+10, Loss_PDE: 5.24444e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.17910e+10, Loss_PDE: 5.17910e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 5.07226e+10, Loss_PDE: 5.07226e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 5.04198e+10, Loss_PDE: 5.04198e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 4.99052e+10, Loss_PDE: 4.99052e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 4.64607e+10, Loss_PDE: 4.64607e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 4.60047e+10, Loss_PDE: 4.60047e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12885e-01\n",
      "Loss: 4.40171e+10, Loss_PDE: 4.40171e+10, Loss_ini: 8.12869e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 3.58829e+10, Loss_PDE: 3.58829e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.56247e+10, Loss_PDE: 3.56247e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 3.53694e+10, Loss_PDE: 3.53694e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.30904e+10, Loss_PDE: 3.30904e+10, Loss_ini: 8.12870e-01, Loss_lbc: 3.12884e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 2.71523e+10, Loss_PDE: 2.71523e+10, Loss_ini: 8.12874e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 2.68818e+10, Loss_PDE: 2.68818e+10, Loss_ini: 8.12874e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 2.56492e+10, Loss_PDE: 2.56492e+10, Loss_ini: 8.12876e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 1.97546e+10, Loss_PDE: 1.97546e+10, Loss_ini: 8.12883e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12895e-01\n",
      "Loss: 1.95532e+10, Loss_PDE: 1.95532e+10, Loss_ini: 8.12883e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12895e-01\n",
      "Loss: 1.86906e+10, Loss_PDE: 1.86906e+10, Loss_ini: 8.12885e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12895e-01\n",
      "Loss: 1.51696e+10, Loss_PDE: 1.51696e+10, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 1.50942e+10, Loss_PDE: 1.50942e+10, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 1.50288e+10, Loss_PDE: 1.50288e+10, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 1.44629e+10, Loss_PDE: 1.44629e+10, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12892e-01\n",
      "Loss: 1.43869e+10, Loss_PDE: 1.43869e+10, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 1.42547e+10, Loss_PDE: 1.42547e+10, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12891e-01\n",
      "Loss: 1.34057e+10, Loss_PDE: 1.34057e+10, Loss_ini: 8.12891e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 1.33291e+10, Loss_PDE: 1.33291e+10, Loss_ini: 8.12891e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 1.31805e+10, Loss_PDE: 1.31805e+10, Loss_ini: 8.12891e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12890e-01\n",
      "Loss: 1.22497e+10, Loss_PDE: 1.22497e+10, Loss_ini: 8.12891e-01, Loss_lbc: 3.12881e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 1.21865e+10, Loss_PDE: 1.21865e+10, Loss_ini: 8.12891e-01, Loss_lbc: 3.12881e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 1.18846e+10, Loss_PDE: 1.18846e+10, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 1.13686e+10, Loss_PDE: 1.13686e+10, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 1.12900e+10, Loss_PDE: 1.12900e+10, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 1.09389e+10, Loss_PDE: 1.09389e+10, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12889e-01\n",
      "Loss: 9.24554e+09, Loss_PDE: 9.24554e+09, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 9.17384e+09, Loss_PDE: 9.17384e+09, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 8.85819e+09, Loss_PDE: 8.85819e+09, Loss_ini: 8.12892e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 6.48023e+09, Loss_PDE: 6.48023e+09, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 6.42634e+09, Loss_PDE: 6.42634e+09, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 6.18691e+09, Loss_PDE: 6.18691e+09, Loss_ini: 8.12890e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 5.08125e+09, Loss_PDE: 5.08125e+09, Loss_ini: 8.12890e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 5.01731e+09, Loss_PDE: 5.01731e+09, Loss_ini: 8.12890e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 4.84936e+09, Loss_PDE: 4.84936e+09, Loss_ini: 8.12890e-01, Loss_lbc: 3.12882e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 4.23707e+09, Loss_PDE: 4.23707e+09, Loss_ini: 8.12889e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 4.16341e+09, Loss_PDE: 4.16341e+09, Loss_ini: 8.12889e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 3.84200e+09, Loss_PDE: 3.84200e+09, Loss_ini: 8.12889e-01, Loss_lbc: 3.12883e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 2.47730e+09, Loss_PDE: 2.47730e+09, Loss_ini: 8.12887e-01, Loss_lbc: 3.12884e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 2.43988e+09, Loss_PDE: 2.43988e+09, Loss_ini: 8.12887e-01, Loss_lbc: 3.12884e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 2.25644e+09, Loss_PDE: 2.25644e+09, Loss_ini: 8.12887e-01, Loss_lbc: 3.12885e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 1.47497e+09, Loss_PDE: 1.47497e+09, Loss_ini: 8.12886e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12886e-01\n",
      "Loss: 1.45744e+09, Loss_PDE: 1.45744e+09, Loss_ini: 8.12886e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 1.37789e+09, Loss_PDE: 1.37789e+09, Loss_ini: 8.12886e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 1.00755e+09, Loss_PDE: 1.00755e+09, Loss_ini: 8.12885e-01, Loss_lbc: 3.12886e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 9.93020e+08, Loss_PDE: 9.93020e+08, Loss_ini: 8.12885e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 9.28692e+08, Loss_PDE: 9.28692e+08, Loss_ini: 8.12885e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 7.01461e+08, Loss_PDE: 7.01461e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 6.86655e+08, Loss_PDE: 6.86655e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 6.53867e+08, Loss_PDE: 6.53867e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12887e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 4.44891e+08, Loss_PDE: 4.44891e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 4.35523e+08, Loss_PDE: 4.35523e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12887e-01\n",
      "Loss: 3.93776e+08, Loss_PDE: 3.93776e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.92989e+08, Loss_PDE: 2.92989e+08, Loss_ini: 8.12884e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.88541e+08, Loss_PDE: 2.88541e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.70938e+08, Loss_PDE: 2.70938e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.86045e+08, Loss_PDE: 1.86045e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.82787e+08, Loss_PDE: 1.82787e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.56009e+08, Loss_PDE: 1.56009e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.52882e+08, Loss_PDE: 1.52882e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.39247e+08, Loss_PDE: 1.39247e+08, Loss_ini: 8.12883e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 7.81572e+07, Loss_PDE: 7.81572e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 7.64850e+07, Loss_PDE: 7.64850e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 6.61782e+07, Loss_PDE: 6.61782e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 6.47637e+07, Loss_PDE: 6.47637e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.69527e+07, Loss_PDE: 5.69527e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.61223e+07, Loss_PDE: 2.61223e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.54691e+07, Loss_PDE: 2.54691e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.26660e+07, Loss_PDE: 2.26660e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.22582e+07, Loss_PDE: 2.22582e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.04665e+07, Loss_PDE: 2.04665e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.21073e+07, Loss_PDE: 1.21073e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.18865e+07, Loss_PDE: 1.18865e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.09186e+07, Loss_PDE: 1.09186e+07, Loss_ini: 8.12882e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.00329e+06, Loss_PDE: 4.00329e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.89536e+06, Loss_PDE: 3.89536e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.43616e+06, Loss_PDE: 3.43616e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.37012e+06, Loss_PDE: 3.37012e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.08174e+06, Loss_PDE: 3.08174e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.73964e+06, Loss_PDE: 1.73964e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.70424e+06, Loss_PDE: 1.70424e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.40736e+06, Loss_PDE: 1.40736e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.37224e+06, Loss_PDE: 1.37224e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.22067e+06, Loss_PDE: 1.22066e+06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.70668e+05, Loss_PDE: 5.70666e+05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.57113e+05, Loss_PDE: 5.57112e+05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.98325e+05, Loss_PDE: 4.98323e+05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.41355e+05, Loss_PDE: 2.41354e+05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.35921e+05, Loss_PDE: 2.35920e+05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.12332e+05, Loss_PDE: 2.12330e+05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.89570e+04, Loss_PDE: 4.89556e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.72835e+04, Loss_PDE: 4.72821e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.37853e+04, Loss_PDE: 3.37838e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.31331e+04, Loss_PDE: 3.31317e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.75590e+04, Loss_PDE: 2.75575e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.70196e+04, Loss_PDE: 2.70181e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 2.24086e+04, Loss_PDE: 2.24072e+04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.40139e+02, Loss_PDE: 4.38700e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.30015e+02, Loss_PDE: 4.28577e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.48394e+02, Loss_PDE: 3.46956e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.43949e+02, Loss_PDE: 3.42511e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 3.24379e+02, Loss_PDE: 3.22941e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.58089e+02, Loss_PDE: 1.56650e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.55792e+02, Loss_PDE: 1.54353e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.45683e+02, Loss_PDE: 1.44244e+02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 6.05097e+01, Loss_PDE: 5.90711e+01, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.94886e+01, Loss_PDE: 5.80499e+01, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.50040e+01, Loss_PDE: 5.35653e+01, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.81728e+01, Loss_PDE: 1.67342e+01, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.78544e+01, Loss_PDE: 1.64157e+01, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.64583e+01, Loss_PDE: 1.50196e+01, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.24738e+00, Loss_PDE: 3.80872e+00, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 5.17267e+00, Loss_PDE: 3.73401e+00, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 4.53375e+00, Loss_PDE: 3.09509e+00, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.45762e+00, Loss_PDE: 1.89584e-02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.45731e+00, Loss_PDE: 1.86576e-02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.45476e+00, Loss_PDE: 1.61058e-02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.45448e+00, Loss_PDE: 1.58216e-02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.45323e+00, Loss_PDE: 1.45744e-02, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.44311e+00, Loss_PDE: 4.44889e-03, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.44303e+00, Loss_PDE: 4.37070e-03, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.44236e+00, Loss_PDE: 3.70074e-03, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43899e+00, Loss_PDE: 3.36012e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43899e+00, Loss_PDE: 3.33233e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43898e+00, Loss_PDE: 3.20864e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43890e+00, Loss_PDE: 2.38988e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43889e+00, Loss_PDE: 2.34244e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43887e+00, Loss_PDE: 2.11272e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43876e+00, Loss_PDE: 1.07705e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43876e+00, Loss_PDE: 1.05551e-04, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43875e+00, Loss_PDE: 9.61184e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43871e+00, Loss_PDE: 5.21545e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43871e+00, Loss_PDE: 5.11054e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43871e+00, Loss_PDE: 4.88136e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43869e+00, Loss_PDE: 3.51544e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43869e+00, Loss_PDE: 3.44430e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43869e+00, Loss_PDE: 3.10475e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.57689e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.54441e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.51641e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.50475e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.47844e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.07580e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 1.05366e-05, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43867e+00, Loss_PDE: 9.56837e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 5.09677e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 4.99159e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 4.91677e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 4.89983e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 4.81750e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 4.81651e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n",
      "Loss: 1.43866e+00, Loss_PDE: 4.81650e-06, Loss_ini: 8.12881e-01, Loss_lbc: 3.12888e-01,Loss_rbc: 3.12888e-01\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss(reduction ='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "loss_history = train_adam(model,loss,optimizer,epochs, nobs,min_param,max_param)\n",
    "\n",
    "optimizer = torch.optim.LBFGS(\n",
    "    model.parameters(), lr=lr, max_iter=50000, max_eval=None, tolerance_grad=1e-5, tolerance_change=1.0 * np.finfo(float).eps,line_search_fn=\"strong_wolfe\" \n",
    "    )\n",
    "\n",
    "loss_history_b = train_LBFGS(model,loss,optimizer, nobs*2,min_param,max_param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
